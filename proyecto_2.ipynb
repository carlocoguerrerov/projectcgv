{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b756ec",
   "metadata": {},
   "source": [
    "# Proyecto Final Tratamiento de Datos\n",
    "\n",
    "Carlos Guerrero Valarezo\n",
    "\n",
    "Maestria Ciberseguridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c89212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.7.3\n",
      "numpy: 1.21.5\n",
      "matplotlib: 3.5.3\n",
      "pandas: 1.3.5\n",
      "statsmodels: 0.13.2\n",
      "sklearn: 1.0.2\n",
      "tensorflow: 2.8.2\n",
      "keras: 2.8.0\n",
      "cv2: 4.6.0\n",
      "re: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "#Versiones que tenemos instaladas en el sistema\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)\n",
    "# statsmodels\n",
    "import statsmodels\n",
    "print('statsmodels: %s' % statsmodels.__version__)\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)\n",
    "# tensorflow\n",
    "import tensorflow\n",
    "print('tensorflow: %s' % tensorflow.__version__)\n",
    "# keras\n",
    "import keras\n",
    "print('keras: %s' % keras.__version__)\n",
    "# cv2\n",
    "import cv2\n",
    "print('cv2: %s' % cv2.__version__)\n",
    "# re\n",
    "import re\n",
    "print('re: %s' % re.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf39210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importacion de Librerias \n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import  Sequential,Input,Model\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "#import\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten #Para la red neuronal\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D #para implementar las capas convolucionales\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac02480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo imagenes de  C:\\Users\\MGZ\\Documents\\GitHub\\projectcgv\\../../../CarneDataset/train\\\n",
      "C:\\Users\\MGZ\\Documents\\GitHub\\projectcgv\\../../../CarneDataset/train\\CLASS_02 1\n",
      "C:\\Users\\MGZ\\Documents\\GitHub\\projectcgv\\../../../CarneDataset/train\\CLASS_03 62\n",
      "C:\\Users\\MGZ\\Documents\\GitHub\\projectcgv\\../../../CarneDataset/train\\CLASS_04 213\n",
      "C:\\Users\\MGZ\\Documents\\GitHub\\projectcgv\\../../../CarneDataset/train\\CLASS_05 105\n",
      "C:\\Users\\MGZ\\Documents\\GitHub\\projectcgv\\../../../CarneDataset/train\\CLASS_06 949\n",
      "C:\\Users\\MGZ\\Documents\\GitHub\\projectcgv\\../../../CarneDataset/train\\CLASS_07 37\n",
      "C:\\Users\\MGZ\\Documents\\GitHub\\projectcgv\\../../../CarneDataset/train\\CLASS_08 204\n",
      "Directorios leidos: 7\n",
      "Imagenes en cada directorio [63, 213, 105, 949, 37, 204, 62]\n",
      "suma Total de imagenes en subdirectorios: 1633\n"
     ]
    }
   ],
   "source": [
    "#Cargar, Contar y Leer fotos de directorio\n",
    "dirname = os.path.join(os.getcwd(), '../../../CarneDataset/train') #Path directorio de Fotos\n",
    "imgpath = dirname + os.sep \n",
    "\n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    "longitud, altura = 200, 200\n",
    "tamano_pool = (2, 2)\n",
    "print(\"Leyendo imagenes de \",imgpath)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant=cant+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath) #cargará a memoria un arreglo de imágenes.\n",
    "            #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #Convertir a escala de grises\n",
    "            image = cv2.GaussianBlur(image, (3, 3), 0)   #Aplicar filtro gaussiano\n",
    "            image = cv2.blur(image, (3, 3))   #Aplicar filtro difuminado\n",
    "            image = cv2.medianBlur(image,5)\n",
    "            image = cv2.resize(image,(longitud,altura))\n",
    "            #image = filters.sobel(image)          \n",
    "            images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)\n",
    "                prevRoot=root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant=0\n",
    "dircount.append(cant)\n",
    "\n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirectorios:',sum(dircount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1277b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  1633\n",
      "0 CLASS_02\n",
      "1 CLASS_03\n",
      "2 CLASS_04\n",
      "3 CLASS_05\n",
      "4 CLASS_06\n",
      "5 CLASS_07\n",
      "6 CLASS_08\n",
      "Cantidad Total de Clases :  7\n",
      "Arreglo de clases creadas :  [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "#Creación de etiquetas\n",
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
    "\n",
    "carnes_clases=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    carnes_clases.append(name[len(name)-1])\n",
    "    indice=indice+1\n",
    "\n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Cantidad Total de Clases : ', nClasses)\n",
    "print('Arreglo de clases creadas : ', classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caaa1854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento Data Shape :  (1306, 200, 200, 3) (1306,)\n",
      "Pruebas Data Shape :  (327, 200, 200, 3) (327,)\n",
      "Etiqueta Original: 5\n",
      "Despues de la conversion one-hot: [0. 0. 0. 0. 0. 1. 0.]\n",
      "(1044, 200, 200, 3) (262, 200, 200, 3) (1044, 7) (262, 7)\n"
     ]
    }
   ],
   "source": [
    "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2) #subdividimos los datos en 80/20 test y entrenamiento\n",
    "print('Entrenamiento Data Shape : ', train_X.shape, train_Y.shape)\n",
    "print('Pruebas Data Shape : ', test_X.shape, test_Y.shape)\n",
    "\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255. #Preprocesamos el valor de los pixeles y lo normalizamos para que tengan un valor entre 0 y 1\n",
    "test_X = test_X / 255.  #Preprocesamos el valor de los pixeles y lo normalizamos para que tengan un valor entre 0 y 1\n",
    "\n",
    "# CAmbiar etiquetas de categorical a one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Mostrar cambio de categoria etiqueta usando one-hot encoding\n",
    "print('Etiqueta Original:', train_Y[0])\n",
    "print('Despues de la conversion one-hot:', train_Y_one_hot[0])\n",
    "\n",
    "\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n",
    "\n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8b9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 67, 67, 32)        896       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 67, 67, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 33, 33, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 33, 33, 64)        8256      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4194560   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,205,511\n",
      "Trainable params: 4,205,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creacion de la Red Convolucional\n",
    "INIT_LR = 1e-3\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "filtros_convo=32\n",
    "filtros_convo2=64\n",
    "tamano_filtro=(3, 3)\n",
    "tamano_filtro2=(2, 2)\n",
    "\n",
    "carnes_model = Sequential() #crear contenedor del modelo, en donde progresivamente se irán añadiendo las capas de la Red Convolucional\n",
    "carnes_model.add(Conv2D(filtros_convo, tamano_filtro,tamano_filtro,padding =\"same\", input_shape=(longitud, altura, 3), activation='linear'))\n",
    "carnes_model.add(LeakyReLU(alpha=0.1))\n",
    "carnes_model.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "carnes_model.add(Conv2D(filtros_convo2, tamano_filtro2, padding =\"same\"))\n",
    "carnes_model.add(MaxPooling2D(pool_size=tamano_pool))\n",
    "carnes_model.add(Flatten())\n",
    "carnes_model.add(Dense(256, activation='linear'))\n",
    "carnes_model.add(Dropout(0.5))\n",
    "carnes_model.add(Dense(nClasses, activation='softmax'))\n",
    "carnes_model.summary()\n",
    "#sgd = SGD(learning_rate=0.1)\n",
    "#carnes_model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,optimizer=tensorflow.keras.optimizers.Adagrad(learning_rate=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])\n",
    "carnes_model.compile (loss='categorical_crossentropy',optimizer=tensorflow.keras.optimizers.Adagrad(learning_rate=INIT_LR, decay=INIT_LR / 100) ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6fc9576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 4s 309ms/step - loss: 1.9322 - accuracy: 0.5086 - val_loss: 1.9130 - val_accuracy: 0.5840\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 2s 272ms/step - loss: 1.9016 - accuracy: 0.5785 - val_loss: 1.8818 - val_accuracy: 0.5840\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 2s 274ms/step - loss: 1.8704 - accuracy: 0.5785 - val_loss: 1.8495 - val_accuracy: 0.5840\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 3s 293ms/step - loss: 1.8359 - accuracy: 0.5785 - val_loss: 1.8109 - val_accuracy: 0.5840\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 3s 293ms/step - loss: 1.7940 - accuracy: 0.5785 - val_loss: 1.7629 - val_accuracy: 0.5840\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 3s 285ms/step - loss: 1.7442 - accuracy: 0.5785 - val_loss: 1.7062 - val_accuracy: 0.5840\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 3s 283ms/step - loss: 1.6856 - accuracy: 0.5785 - val_loss: 1.6418 - val_accuracy: 0.5840\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 2s 276ms/step - loss: 1.6281 - accuracy: 0.5785 - val_loss: 1.5831 - val_accuracy: 0.5840\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 3s 281ms/step - loss: 1.5697 - accuracy: 0.5785 - val_loss: 1.5268 - val_accuracy: 0.5840\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 3s 293ms/step - loss: 1.5216 - accuracy: 0.5785 - val_loss: 1.4829 - val_accuracy: 0.5840\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 3s 311ms/step - loss: 1.4810 - accuracy: 0.5785 - val_loss: 1.4487 - val_accuracy: 0.5840\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 1.4517 - accuracy: 0.5785 - val_loss: 1.4238 - val_accuracy: 0.5840\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 3s 290ms/step - loss: 1.4315 - accuracy: 0.5785 - val_loss: 1.4085 - val_accuracy: 0.5840\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 3s 291ms/step - loss: 1.4243 - accuracy: 0.5785 - val_loss: 1.3965 - val_accuracy: 0.5840\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 1.4174 - accuracy: 0.5785 - val_loss: 1.3889 - val_accuracy: 0.5840\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 3s 293ms/step - loss: 1.4120 - accuracy: 0.5785 - val_loss: 1.3833 - val_accuracy: 0.5840\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 1.4023 - accuracy: 0.5785 - val_loss: 1.3780 - val_accuracy: 0.5840\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 1.4048 - accuracy: 0.5785 - val_loss: 1.3748 - val_accuracy: 0.5840\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 3s 278ms/step - loss: 1.3992 - accuracy: 0.5785 - val_loss: 1.3710 - val_accuracy: 0.5840\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 3s 285ms/step - loss: 1.3922 - accuracy: 0.5785 - val_loss: 1.3672 - val_accuracy: 0.5840\n"
     ]
    }
   ],
   "source": [
    "carnes_train_dropout = carnes_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    "# Guardamos la informacion para no volver a generar en el futuro\n",
    "carnes_model.save('./modelo/modelo.h5')\n",
    "carnes_model.save_weights('./modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = carnes_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    "\n",
    " \n",
    "\n",
    "print('Test Red CNN:')\n",
    "\n",
    "print('Perdida:', test_eval[0])\n",
    "\n",
    "print('Exactitud:', test_eval[1])\n",
    "\n",
    " \n",
    "\n",
    "accuracy = carnes_train_dropout.history['accuracy']\n",
    "\n",
    "val_accuracy = carnes_train_dropout.history['val_accuracy']\n",
    "\n",
    "loss = carnes_train_dropout.history['loss']\n",
    "\n",
    "val_loss = carnes_train_dropout.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'bo', label='Precision de entrenamiento')\n",
    "\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Exactitud de la validacion')\n",
    "\n",
    "plt.title('Precisión de entrenamiento y validación')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Perdida de entrenamiento')\n",
    "\n",
    "plt.plot(epochs, val_loss, 'b', label='Perdida de validacion')\n",
    "\n",
    "plt.title('Perdida de entrenamiento y validacion')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "longitud, altura = 200, 200\n",
    "modelo = './modelo/modelo.h5'\n",
    "pesos_modelo = './modelo/pesos.h5'\n",
    "cnn = load_model(modelo)\n",
    "cnn.load_weights(pesos_modelo)\n",
    "\n",
    "def predict(file):\n",
    "  x = load_img(file, target_size=(longitud, altura))\n",
    "  x = img_to_array(x)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  array = cnn.predict(x)\n",
    "  result = array[0]\n",
    "  answer = np.argmax(result)\n",
    "  if answer == 0:\n",
    "    print(\"Pertenece a CLASS_02\")\n",
    "  elif answer == 1:\n",
    "    print(\"Pertenece a CLASS_03\")\n",
    "  elif answer == 2:\n",
    "    print(\"Pertenece a CLASS_04\")\n",
    "  elif answer == 3:\n",
    "    print(\"Pertenece a CLASS_05\")\n",
    "  elif answer == 4:\n",
    "    print(\"Pertenece a CLASS_06\")\n",
    "  elif answer == 5:\n",
    "    print(\"Pertenece a CLASS_07\")\n",
    "  elif answer == 6:\n",
    "    print(\"Pertenece a CLASS_08\")\n",
    "  else :\n",
    "    print(\"Pertenece a CLASS_01\")\n",
    "  return answer\n",
    "\n",
    "predict (\"14-CAPTURE_20220523_141530_080.png\")\n",
    "predict (\"1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6aeb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
